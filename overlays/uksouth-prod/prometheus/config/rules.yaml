---
groups:

# Set London time
  - name: daylight_saving
    rules:
      - record: is_european_summer_time
        expr: |
          (vector(1) and (month() > 3 and month() < 10))
          or
          (vector(1) and (month() == 3 and (day_of_month() - day_of_week()) >= 25) and absent((day_of_month() >= 25) and (day_of_week() == 0)))
          or
          (vector(1) and (month() == 10 and (day_of_month() - day_of_week()) < 25) and absent((day_of_month() >= 25) and (day_of_week() == 0)))
          or
          (vector(1) and ((month() == 10 and hour() < 1) or (month() == 3 and hour() > 0)) and ((day_of_month() >= 25) and (day_of_week() == 0)))
          or
          vector(0)
      - record: europe_london_hour
        expr: hour() + is_european_summer_time

  - name: Infrastructure
    rules:
      - alert: Unavailable Replicas
        expr: sum by(deployment, namespace) (kube_deployment_status_replicas_unavailable) > 0
        for: 1m
        labels:
          severity: p2
          cluster: prod
          component: Kubernetes
          resolve: true
        annotations:
          title: 'Prod - {{ $labels.deployment}}'
          description: 'Deployment: {{ $labels.deployment}} in Namespace: {{$labels.namespace}} has unavailable replicas.'

      - alert: Container Restarts
        expr: increase(kube_pod_container_status_restarts_total[5m]) > 0
        for: 1s
        labels:
          severity: p2
          cluster: prod
          resolve: true
          component: Kubernetes
        annotations:
          title: 'Prod - Container restarts'
          description: 'Container: {{$labels.container}} in Deploy: {{$labels.pod}} in Namespace: {{$labels.namespace}} is restarting alot'

      - alert: Kube pod waiting status
        expr: sum by (reason, pod)(kube_pod_container_status_waiting_reason) > 0
        for: 1m
        labels: 
          severity: p2
          cluster: prod
          resolve: true
          component: Kubernetes
        annotations:  
          title: 'Prod - Pod waiting status'
          description: 'Pod: {{$labels.pod}} is in this State: {{$labels.reason}} in this Namespace: {{$labels.namespace}}'
      
      - alert: Rabbitmq Queue Length
        expr: sum by(queue)(rabbitmq_queue_messages_ready) > 100
        for: 5m
        labels:
          severity: p2
          cluster: prod
          resolve: false
          component: Rabbitmq
        annotations: 
          title: 'Rabbitmq queue length over 100 ready tasks'
          description: '{{$labels.queue}} queue has been at over 100 tasks for 5 mins' 

      # - alert: core sftp up state
      #   expr: up{job="azure_node",name=~"sftp\\d"} < 1
      #   for: 3m
      #   labels:
      #     severity: S1
      #   annotations:
      #     resource: '{{ $labels.name }}'
      #     summary: Check sftp virtual machines - bad up state for over 3 minutes

  - name: Service Team
    rules:
      - alert: Exported transactions
        expr: sum(increase(transactions_total{slug!="iceland-bonus-card"}[2h])) by (slug) < 1 and europe_london_hour != 12 < 23
        for: 1m
        labels:
          severity: p2
          cluster: prod
          component: harmonia
          resolve: false
        annotations:
          resource: '{{ $labels.slug }}'
          sumamry: 'There have been no exports between 12:00 and 23:00'
      
      - alert: Payment cards processing slowly
        expr: (sum(payment_card_processing_seconds_histogram_sum{}) by (provider) / sum(payment_card_processing_seconds_histogram_count{}) by (provider)) > 5
        for: 5m
        labels:
          severity: p2
          cluster: prod
          component: hermes
          resolve: false
        annotations:
          summany: 'Payment cards for {{ $labels.provider }} are taking longer than
            four seconds to process.'
      
      - alert: Payment cards stuck increase
        expr: sum by (provider) (hermes_current_payment_card_pending_overdue_total{}) > sum by (provider) (hermes_current_payment_card_pending_overdue_total{} offset 24h +15)
        for: 5m
        labels:
          severity: p2
          cluster: prod
          component: asteria
          resolve: false
        annotations:
          resource: '{{$labels.provider}}'
          summary: Payment cards have been stuck in a pending state for more than 24 hours

      - alert: Vop status stuck in transitory state
        expr: sum by (status)(hermes_current_vop_activation_status_total{status=~"Deactivating|Activating"}) > sum by (status)(hermes_current_vop_activation_status_total{status=~"Deactivating|Activating"} offset 15m)
        for: 15m
        labels:
          severity: p2
          cluster: prod
          component: asteria
          resolve: false
        annotations:
          resource: '{{$labels.status}}'
          summary: VOP account status in {{$labels.status}} state for over 15 minutes - check

      - alert: Failed exports - receipt number not found
        expr: sum(failed_requests_total{response_result="receipt no not found"}) > 500
        for: 1m
        labels:
          severity: p2
          cluster: prod
          component: harmonia
          resolve: false
        annotations:
          resource: '{{ $labels.view }} - {{ $labels.status }} - {{ $labels.slug }} - {{ $labels.response_result }}'
          summary: There have been failed exports from harmonia returning receipt not found.

      - alert: Failed exports excluding receipt not found
        expr: sum(failed_requests_total{response_result!="receipt no not found"}) > 100
        for: 1m
        labels:
          severity: p2
          cluster: prod
          component: harmonia
          resolve: false
        annotations:
          resource: '{{ $labels.view }} - {{ $labels.status }} - {{ $labels.slug }} - {{ $labels.response_result }}'
          summary: There have been failed exports from harmonia.

      - alert: Failed exports - "an error has occured"
        expr: sum(increase(failed_requests_total{response_result="an error has occurred."} [10m])) > 0
        for: 1m
        labels:
          severity: p2
          cluster: prod
          component: harmonia
          resolve: false
        annotations:
          resource: '{{ $labels.view }} - {{ $labels.status }} - {{ $labels.slug }} - {{ $labels.response_result }}'
          summary: There have been failed exports for wasabi.

      - alert: midas - failed http requests to merchants
        expr: sum(increase(request_fail_total{}[1h]))
          by (error, slug) > 6
        for: 90m
        labels:
          severity: p2
          cluster: prod
          resolve: false
        annotations:
          resource: '{{ $labels.slug }} - {{ $labels.error }}'
          summary: There has been an increase in failed HTTP requests from Midas to {{$labels.slug}}

      - alert: midas - failed login is increasing
        expr: sum(increase(log_in_fail_total{}[10m])) by (slug) > 5
        for: 15m
        labels:
          severity: p2
          ckuster: prod
          resolve: false
        annotations:
          resource: '{{ $labels.slug }}'
          summary: There has been an increase of 5 in failed logins in 10 mins

      # - alert: Files not received - wasabi
      #   expr: (increase(blobstorage_files_total{name="wasabihack"}[46m]) or on() vector(0)) < 1
      #   for: 3m
      #   labels:
      #     severity: S2
      #   annotations:
      #     resource: '{{ $labels.name }}'
      #     summary: Three missing files over 45 minute period - check latest Wasabi import (Transaction log lands every 15 minutes between the hours of 12pm and 8pm)

# Alerts for the state of our certificates
  - name: Certificates
    rules:
      - alert: core ssl external (non-letsencrypt) 10 days
        expr: ((ssl_cert_not_after{cn!~".*(COMODO RSA Domain Validation|Sectigo RSA
          Domain Validation|RSA Certification Authority|Let's Encrypt Authority X3|R3).*",issuer_cn!~".*(Let's
          Encrypt|COMODO RSA Domain Validation|R3).*"} - time()) / 24 / 60 / 60) <
          10
        labels:
          severity: p1
          cluster: prod
          resolve: false
        annotations:
          resource: '{{ $labels.instance }}'
          summary: Cert less than 10 days from expiring

      - alert: core ssl external (non-letsencrypt) 30 days
        expr: ((ssl_cert_not_after{cn!~".*(COMODO RSA Domain Validation|Sectigo RSA
          Domain Validation|RSA Certification Authority|Let's Encrypt Authority X3|R3).*",issuer_cn!~".*(Let's
          Encrypt|COMODO RSA Domain Validation|R3).*"} - time()) / 24 / 60 / 60) <
          30
        labels:
          severity: p2
          cluster: prod
          resolve: false
        annotations:
          resource: '{{ $labels.instance }}'
          summary: Cert less than 30 days from expiring

      - alert: core ssl external (letsencrypt) 05 days
        expr: ((ssl_cert_not_after{cn!~".*(COMODO RSA Domain Validation|Sectigo RSA
          Domain Validation|RSA Certification Authority|Let's Encrypt Authority X3).*",issuer_cn=~".*(Let's
          Encrypt|R3).*"} - time())/24/60/60) < 5
        labels:
          severity: p1
          cluster: prod
          resolve: false
        annotations:
          resource: '{{ $labels.instance }}'
          summary: Let's Encrypt cert less than 05 days from expiring

      - alert: core ssl external (letsencrypt) 10 days
        expr: ((ssl_cert_not_after{cn!~".*(COMODO RSA Domain Validation|Sectigo RSA
          Domain Validation|RSA Certification Authority|Let's Encrypt Authority X3).*",issuer_cn=~".*(Let's
          Encrypt|R3).*"} - time())/24/60/60) < 10
        labels:
          severity: p2
          cluster: prod
          resolve: false
        annotations:
          summary: Let's Encrypt cert less than 10 days from expiring

      - alert: core ssl kubernetes internal (letsencrypt) 05 days
        expr: (certmanager_certificate_expiration_timestamp_seconds - time())/24/60/60
          < 5
        labels:
          severity: p1
          cluster: prod
          resolve: false
        annotations:
          resource: '{{ $labels.name }}'
          summary: Let's Encrypt Kubernetes cert less than 05 days from expiring

      - alert: core ssl kubernetes internal (letsencrypt) 10 days
        expr: (certmanager_certificate_expiration_timestamp_seconds - time())/24/60/60
          < 10
        labels:
          severity: p2
          cluster: prod
          resolve: false
        annotations:
          resource: '{{ $labels.name }}'
          summary: Let's Encrypt Kubernetes cert less than 10 days from expiring



          
  # - name: Testing
  #   rules:
  #     - alert: core test alerting and callout chain (should be red)
  #       expr: ({job="always_alert"} OR on() vector(0)) == 0
  #       for: 1m
  #       labels:
  #         severity: p1
  #         cluster: prod
  #         testing: true
  #         callout: true
  #       annotations: 
  #         summary: This alert will test the Prometheus --> Alertmanager connectivity
