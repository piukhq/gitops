groups:
- name: dev
  rules:
  - alert: dev kube controller up state
    expr: (up{job="azure_node",name="dev0-controller"} OR on() vector(0)) < 1
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine controller - bad up state for over 5 minutes

  - alert: dev kube worker pool depleted
    expr: (sum(up{job="azure_node",name=~"dev0-vmss_.+"}) OR on() vector(0)) < 2
    for: 3m
    labels:
      severity: S3
    annotations:
      summary: Check dev0 cluster - worker count less than 2
      
  - alert: dev kube worker up state
    expr: (up{job="azure_node",name=~"dev0-vmss_.+"} OR on() vector(0)) < 1
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine worker - bad up state for over 5 minutes

  - alert: dev media backup tar file size
    expr: (100 * (1 - ((backup_utility_file_size{kubernetes_cluster="dev0",type="media"} offset 24h) / (backup_utility_file_size{kubernetes_cluster="dev0",type="media"}))) < -50) or (100 * (1 - ((backup_utility_file_size{kubernetes_cluster="dev0",type="media"} offset 24h) / (backup_utility_file_size{kubernetes_cluster="dev0",type="media"}))) > 50)
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.name }}"
      summary: Raw dev media backup file size has increased/decreased by over 50% within an 8 day window

  - alert: dev media backup uploads (weekly)
    expr: sum(increase(backup_utility_upload_to_blob_count_total{kubernetes_cluster="dev0",type="media"}[8d])) < 1
    for: 1d
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.type }} - {{ $labels.schedule }}"
      summary: Backup tar file failed to upload from backup-scheduler pod to binkuksouthdev/backups storage account

  - alert: dev nginx ingress up state
    expr: (sum(up{kubernetes_cluster="dev0",kubernetes_pod_name=~"ingress-nginx-controller.+"}) OR on() vector(0)) < 2
    for: 3m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.instance }}"
      summary: Check dev nginx ingress - bad upstate on one or more pods for over 3 minutes
      
  - alert: dev postgres backup failure
    expr: increase(backup_utility_file_count_total{job="backup-scheduler",resource=~"bink-uksouth-dev-.+",status="failed",type="postgres"}[61m]) > 1
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.name }} - {{ $labels.schedule }}"
      summary: Check dev backup-scheduler pod and binkuksouthdev/backups storage account - potential backup failure

  - alert: dev postgres backup sql file size
    expr: (100 * (1 - ((backup_utility_file_size{resource=~"bink-uksouth-dev-.+"} offset 24h) / (backup_utility_file_size{resource=~"bink-uksouth-dev-.+"}))) < -50) or (100 * (1 - ((backup_utility_file_size{resource=~"bink-uksouth-dev-.+"} offset 24h) / (backup_utility_file_size{resource=~"bink-uksouth-dev-.+"}))) > 50)
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.name }}"
      summary: Raw dev postgres backup file size has increased/decreased by over 50% within 24 hour window

  - alert: dev postgres backup uploads (hourly)
    expr: sum(increase(backup_utility_upload_to_blob_count_total{resource="binkuksouthdev",schedule="hourly",type="postgres"}[61m])) < 1
    for: 90m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.type }} - {{ $labels.schedule }}"
      summary: Backup tar file failed to upload from backup-scheduler pod to binkuksouthdev/backups storage account

  - alert: dev postgres backup uploads (weekly)
    expr: sum(increase(backup_utility_upload_to_blob_count_total{resource="binkuksouthdev",schedule="weekly",type="postgres"}[8d])) < 1
    for: 1d
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.type }} - {{ $labels.schedule }}"
      summary: Backup tar file failed to upload from backup-scheduler pod to binkuksouthdev/backups storage account

  - alert: dev postgres cpu
    expr: cpu_percent_percent_max{resource_group="uksouth-dev",resource_name="bink-uksouth-dev-common"} > 90
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.resource_name }}"
      summary: Check dev postgres - CPU over 90% for 5 minutes

  - alert: dev postgres storage
    expr: storage_percent_percent_max{resource_group="uksouth-dev",resource_name="bink-uksouth-dev-common"} > 90
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.resource_name }}"
      summary: Check dev postgres - storage over 90% for 5 minutes

  - alert: dev postgres up state
    expr: (up{instance="bink-uksouth-dev-common",job="postgres"} OR on() vector(0)) < 1
    for: 3m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.instance }}"
      summary: Check dev postgres - bad upstate for over 3 minutes

  # - alert: dev rabbitmq up state
  #   expr: (sum(up{kubernetes_cluster="dev0",kubernetes_pod_name=~"rabbitmq-\\d"}) OR on() vector(0)) < 1
  #   for: 3m
  #   labels:
  #     severity: S3
  #   annotations:
  #     resource: "{{ $labels.instance }}"
  #     summary: Check dev rabbitmq - bad upstate for over 3 minutes

  - alert: dev virtual machines cpu
    expr: 100 - (avg by (name) (irate(node_cpu_seconds_total{job="azure_node",name=~"dev0-.+",mode="idle"}[5m])) * 100) > 90
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine - CPU over 90% for over 5 minutes

  - alert: dev virtual machines memory
    expr: node_memory_MemAvailable_bytes{job="azure_node",name=~"dev0-.+"} < 100000000
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine - Available memory < 100MB for over 5 minutes

  - alert: dev virtual machines root filesystem
    expr: 100 - ((node_filesystem_avail_bytes{job="azure_node",name=~"dev0-.+",mountpoint="/"} * 100) / node_filesystem_size_bytes{job="azure_node",name=~"dev0-.+",mountpoint="/"}) > 90
    for: 5m
    labels:
      severity: S3
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machines - Root filesystem over 90% used for over 5 minutes


