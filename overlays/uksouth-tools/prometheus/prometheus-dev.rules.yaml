groups:
- name: dev
  rules:
  - alert: dev media backup tar file size
    expr: (100 * (1 - ((backup_utility_file_size{kubernetes_cluster="dev0",type="media"} offset 24h) / (backup_utility_file_size{kubernetes_cluster="dev0",type="media"}))) < -50) or (100 * (1 - ((backup_utility_file_size{kubernetes_cluster="dev0",type="media"} offset 24h) / (backup_utility_file_size{kubernetes_cluster="dev0",type="media"}))) > 50)
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Raw dev media backup file size has increased/decreased by over 50% within an 8 day window

  - alert: dev media backup uploads (weekly)
    expr: (increase(backup_utility_upload_to_blob_count_total{kubernetes_cluster="dev0",type="media"}[8d]) OR on() vector(0)) < 1
    for: 8d
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.type }} - {{ $labels.schedule }}"
      summary: Backup tar file failed to upload from backup-scheduler pod to binkuksouthdev/backups storage account

  - alert: dev postgres backup failure
    expr: increase(backup_utility_file_count_total{job="backup-scheduler",resource=~"bink-uksouth-dev-.+",status="failed",type="postgres"}[61m]) > 1
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.name }} - {{ $labels.schedule }}"
      summary: Check dev backup-scheduler pod and binkuksouthdev/backups storage account - potential backup failure

  - alert: dev postgres backup sql file size
    expr: (100 * (1 - ((backup_utility_file_size{resource=~"bink-uksouth-dev-.+"} offset 24h) / (backup_utility_file_size{resource=~"bink-uksouth-dev-.+"}))) < -50) or (100 * (1 - ((backup_utility_file_size{resource=~"bink-uksouth-dev-.+"} offset 24h) / (backup_utility_file_size{resource=~"bink-uksouth-dev-.+"}))) > 50)
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Raw dev postgres backup file size has increased/decreased by over 50% within 24 hour window

  - alert: dev postgres backup uploads (hourly)
    expr: (increase(backup_utility_upload_to_blob_count_total{resource="binkuksouthdev",schedule="hourly",type="postgres"}[61m]) OR on() vector(0)) < 1
    for: 90m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.type }} - {{ $labels.schedule }}"
      summary: Backup tar file failed to upload from backup-scheduler pod to binkuksouthdev/backups storage account

  - alert: dev postgres cpu
    expr: cpu_percent_percent_max{resource_group="uksouth-dev",resource_name="bink-uksouth-dev-common"} > 90
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.resource_name }}"
      summary: Check dev postgres - CPU over 90% for 5 minutes

  - alert: dev postgres storage
    expr: storage_percent_percent_max{resource_group="uksouth-dev",resource_name="bink-uksouth-dev-common"} > 90
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.resource_name }}"
      summary: Check dev postgres - storage over 90% for 5 minutes

  - alert: dev postgres up state
    expr: up{job="postgres",instance="bink-uksouth-dev-common"} < 1
    for: 3m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.instance }}"
      summary: Check dev postgres - bad upstate for over 3 minutes

  - alert: dev redis cpu
    expr: serverload_percent_max{resource_group="uksouth-dev",resource_name="bink-uksouth-dev-common"} > 90
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.resource_name }}"
      summary: Check dev redis - CPU over 90% for over 5 minutes

  - alert: dev redis memory
    expr: 100 * (usedmemory_bytes_max{resource_group="uksouth-dev",resource_name="bink-uksouth-dev-common"} / 1000000000) > 90
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.resource_name }}"
      summary: Check dev redis - memory over 90% for over 5 minutes

  - alert: dev redis up state
    expr: redis_up{instance=~"bink-uksouth-dev.+"} < 1
    for: 3m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.instance }}"
      summary: Check dev redis - bad upstate for over 3 minutes

  - alert: dev virtual machines cpu
    expr: 100 - (avg by (name) (irate(node_cpu_seconds_total{job="azure_node",env="Development",mode="idle"}[5m])) * 100) > 90
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine - CPU over 90% for over 5 minutes

  - alert: dev virtual machines memory
    expr: node_memory_MemAvailable_bytes{job="azure_node",env="Development"} < 100000000
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine - Available memory < 100MB for over 5 minutes

  - alert: dev virtual machines root filesystem
    expr: 100 - ((node_filesystem_avail_bytes{job="azure_node",env="Development",mountpoint="/"} * 100) / node_filesystem_size_bytes{job="azure_node",env="Development",mountpoint="/"}) > 90
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machines - Root filesystem over 90% used for over 5 minutes

  - alert: dev virtual machines up state
    expr: up{job="azure_node",env="Development"} < 1
    for: 5m
    labels:
      severity: P2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine - bad up state for over 5 minutes

  - alert: dev0 worker pool depleted
    expr: 100 * (sum(up{job="azure_node",name=~"dev0-worker\\d\\d"}) / count(up{job="azure_node",name=~"dev0-worker\\d\\d"})) <= 60
    for: 3m
    labels:
      severity: P2
    annotations:
      summary: Check dev0 workers - pool depleted by at least 40%

  - alert: Nginx Ingress
    expr: sum(up{kubernetes_cluster="dev",kubernetes_pod_name=~"nginx-ingress-controller.+"}) < 1
    for: 1m
    labels:
      severity: P2
    annotations:
      summary: No Ingress Nginx pods running

  - alert: RabbitMQ
    expr: sum(up{kubernetes_cluster="dev",job="rabbitmq"}) < 1
    for: 1m
    labels:
      severity: P2
    annotations:
      summary: RabbitMQ not running
