groups:
- name: staging
  rules:
  - alert: staging kube controller up state
    expr: (up{job="azure_node",name="staging0-controller"} OR on() vector(0)) < 1
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine controller - bad up state for over 5 minutes

  - alert: staging kube worker pool depleted
    expr: (sum(up{job="azure_node",name=~"staging0-vmss_.+"}) OR on() vector(0)) < 2
    for: 3m
    labels:
      severity: S2
    annotations:
      summary: Check staging0 cluster - worker count less than 2

  - alert: staging kube worker up state
    expr: (up{job="azure_node",name=~"staging0-vmss_.+"} OR on() vector(0)) < 1
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine worker - bad up state for over 5 minutes

  - alert: staging media backup tar file size
    expr: (100 * (1 - ((backup_utility_file_size{kubernetes_cluster="staging0",type="media"} offset 24h) / (backup_utility_file_size{kubernetes_cluster="staging0",type="media"}))) < -50) or (100 * (1 - ((backup_utility_file_size{kubernetes_cluster="staging0",type="media"} offset 24h) / (backup_utility_file_size{kubernetes_cluster="staging0",type="media"}))) > 50)
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Raw staging media backup file size has increased/decreased by over 50% within an 8 day window

  - alert: staging media backup uploads (weekly)
    expr: (increase(backup_utility_upload_to_blob_count_total{kubernetes_cluster="staging0",type="media"}[8d]) OR on() vector(0)) < 1
    for: 8d
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.type }} - {{ $labels.schedule }}"
      summary: Backup tar file failed to upload from backup-scheduler pod to binkuksouthstaging/backups storage account

  - alert: staging nginx ingress up state
    expr: (sum(up{kubernetes_cluster="staging0",kubernetes_pod_name=~"ingress-nginx-controller.+"}) OR on() vector(0)) < 2
    for: 3m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.instance }}"
      summary: Check staging nginx ingress - bad upstate on one or more pods for over 3 minutes

  - alert: staging postgres backup failure
    expr: increase(backup_utility_file_count_total{job="backup-scheduler",resource=~"bink-uksouth-staging-.+",status="failed",type="postgres"}[61m]) > 1
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check staging backup-scheduler pod and binkuksouthstaging/backups storage account - potential backup failure

  - alert: staging postgres backup sql file size
    expr: (100 * (1 - ((backup_utility_file_size{resource=~"bink-uksouth-staging-.+"} offset 24h) / (backup_utility_file_size{resource=~"bink-uksouth-staging-.+"}))) < -20) or (100 * (1 - ((backup_utility_file_size{resource=~"bink-uksouth-staging-.+"} offset 24h) / (backup_utility_file_size{resource=~"bink-uksouth-staging-.+"}))) > 20)
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Raw staging postgres backup file size has increased/decreased by over 20% within 24 hour window

  - alert: staging postgres backup uploads (hourly)
    expr: (increase(backup_utility_upload_to_blob_count_total{resource="binkuksouthstaging",schedule="hourly",type="postgres"}[61m]) OR on() vector(0)) < 1
    for: 90m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.type }} - {{ $labels.schedule }}"
      summary: Backup tar file failed to upload from backup-scheduler pod to binkuksouthstaging/backups storage account

  - alert: staging postgres cpu
    expr: cpu_percent_percent_max{resource_name="bink-uksouth-staging-common"} > 90
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.resource_name }}"
      summary: Check staging postgres - CPU over 90% for 5 minutes

  - alert: staging postgres storage
    expr: storage_percent_percent_max{resource_name="bink-uksouth-staging-common"} > 90
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.resource_name }}"
      summary: Check staging postgres - storage over 90% for 5 minutes

  - alert: staging postgres up state
    expr: (up{instance="bink-uksouth-staging-common",job="postgres"} OR on() vector(0)) < 1
    for: 3m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.instance }}"
      summary: Check staging postgres - bad upstate for over 3 minutes

  - alert: staging rabbitmq up state
    expr: (sum(up{kubernetes_cluster="staging0",kubernetes_pod_name=~"rabbitmq-\\d"}) OR on() vector(0)) < 1
    for: 3m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.instance }}"
      summary: Check staging rabbitmq - bad upstate for over 3 minutes

  - alert: staging virtual machines cpu
    expr: 100 - (avg by (name) (irate(node_cpu_seconds_total{job="azure_node",name=~"staging0-.+",mode="idle"}[5m])) * 100) > 90
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine - CPU over 90% for over 5 minutes

  - alert: staging virtual machines memory
    expr: node_memory_MemAvailable_bytes{job="azure_node",name=~"staging0-.+"} < 100000000
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machine - Available memory < 100MB for over 5 minutes

  - alert: staging virtual machines root filesystem
    expr: 100 - ((node_filesystem_avail_bytes{job="azure_node",name=~"staging0-.+",mountpoint="/"} * 100) / node_filesystem_size_bytes{job="azure_node",name=~"staging0-.+",mountpoint="/"}) > 90
    for: 5m
    labels:
      severity: S2
    annotations:
      resource: "{{ $labels.name }}"
      summary: Check virtual machines - Root filesystem over 90% used for over 5 minutes